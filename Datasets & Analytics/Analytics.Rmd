---
title: "AOL"
author: "Gabriella Clairine, Zaneta Fransiske, Grace Esther"
date: "2024-04-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
source("explorationFunction.R")
library(ggplot2) # data viz
library(dplyr) # data manipulation
library(corrplot) # visualizing correlation matrices
library(ltm) # Item Reponse Theory -> biserial.cor
library(vcd) # Categorical Data Visualization -> assocstats
library(DescTools) # miscellaneous functions for descriptive statistics -> PercTable
library(ggridges) # ridge plots -> geom_density_ridges
```

Based on the third SDG, health and well-being, this EDA focuses on 'well-being in the midst of the Covid-19 pandemic'. The dataset includes information on individuals' daily activities, health problems and stress relievers. It aims to provide insights that can contribute to improving mental and physical health, in line with the SDG goal of ensuring healthy lives and promoting well-being for all at all ages.

```{r}
# import data from directory in data frame format
df.raw <- read.csv("COVID-19 Survey Student Responses.csv")
head(df.raw, n=10)
```

```{r}
# showing the structure of our dataframe
str(df.raw)
```
df.raw is a data frame with 1182 observations/ rows with 19 features/ variables it tell which variables has what type of variables (chr: character/ string, int: whole number, num: numeric) it also shows some of the value of each variables

Variable Description:

1. ID: Unique identifier for each observation.
2. Region.of.residence: The residential region of the respondent.
3. Age.of.Subject: The age of the respondent.
4. Time.spent.on.Online.Class: Duration of time spent on online classes.
5. Rating.of.Online.Class.experience: Rating of the online class experience.
6. Medium.for.online.class: The device used for attending online classes.
7. Time.spent.on.self.study: Duration of time spent on self-study.
8. Time.spent.on.fitness: Duration of time spent on fitness-related activities.
9. Time.spent.on.sleep: Duration of sleep.
10. Time.spent.on.social.media: Duration of time spent on social media.
11. Prefered.social.media.platform: Preferred social media platform.
12. Time.spent.on.TV: Duration of time spent watching TV.
13. Number.of.meals.per.day: Number of meals consumed per day.
14. Change.in.your.weight: Change in weight.
15. Health.issue.during.lockdown: Whether the respondent experienced health issues during the lockdown.
16. Stress.busters: Activities used as stress busters.
17. Time.utilized: Whether the respondent utilized their time effectively.
18. Do.you.find.yourself.more.connected.with.your.family..close.friends...relatives...: Whether the respondent felt more connected with family, friends, or relatives.
19. What.you.miss.the.most: What the respondent missed the most during the lockdown.

```{r}
# using dplyr library to rename the columns name's
# the left side is the new column name and the right side is the old column name
df.raw = df.raw %>% rename(
  Region = Region.of.residence,
  Age = Age.of.Subject,
  OnlineClass_Time = Time.spent.on.Online.Class,
  OnlineClass_Rating = Rating.of.Online.Class.experience,
  OnlineClass_Medium = Medium.for.online.class,
  SelfStudy_Duration = Time.spent.on.self.study,
  Fitness_Duration = Time.spent.on.fitness,
  Sleeping_Duration = Time.spent.on.sleep,
  SosMed_Duration = Time.spent.on.social.media,
  SosMed_Medium = Prefered.social.media.platform,
  WatchingTV_Duration = Time.spent.on.TV,
  NumberOfMeals = Number.of.meals.per.day,
  WeightChange = Change.in.your.weight,
  Having_HealthIssue = Health.issue.during.lockdown,
  Stress_Busters = Stress.busters,
  Time_Utilized = Time.utilized,
  Connected_with_Family_Friends_Relatives = Do.you.find.yourself.more.connected.with.your.family..close.friends...relatives...,
  Most_Missed_Things = What.you.miss.the.most
)

```

```{r}
# create a new data frame from subsetting our old data frame and remove the ID column because we think that ID column isn't useful
df <- subset(df.raw, select = -c(ID))

# checking our new data frame structure's
str(df)
```

```{r}
# function to print the unique value and the total of unique value count in specific column (the column name will be passed as parameter)
CekUnique <- function(i)
{
  # cat is a function which stands for concatenate and print
    cat(i,": [",length(unique(df[[i]])),"]\n") # the total of unique value count
    cat(unique(df[[i]]), sep = "; ") # unique value
    cat("\n\n")
}

# names will store all the column's name in our dataframe
for (i in names(df)) CekUnique(i) # check unique for all columns in our data frame
```

This is useful for data pre processing so that we know if there is inconsistency or incompleteness

Change the "none" value with NA , handle the inconsistency of data value

```{r}
df$SosMed_Medium[df$SosMed_Medium %in% c("None", "None ")] <- NA
df$SosMed_Medium[df$SosMed_Medium == "Whatsapp"] <- "WhatsApp"
df$WatchingTV_Duration[df$WatchingTV_Duration %in% c("N", "n", " ", "")] <- NA
df$WatchingTV_Duration[df$WatchingTV_Duration=="No tv"] <- 0
df$Most_Missed_Things[df$Most_Missed_Things %in% c("All ", "all", "All of the above ", "All the above", "ALL", "everything", "all of the above", "All above", "All of them")] <- "All"
df$Most_Missed_Things[df$Most_Missed_Things %in% c("NOTHING", "I have missed nothing ", "nothing", "Nothing this is my usual life", "Nothing ", ".")] <- "Nothing"
```

Fixing the wrong data type

```{r}
# Change the datatype from char to numeric
df$WatchingTV_Duration = as.numeric(df$WatchingTV_Duration)
```

```{r}
# choose the name of columns which datatype is numeric/ integer or categorical/ char
num_cols = c()
cat_cols = c()
for (i in names(df))
{
  if (is.numeric(df[[i]]) || is.integer(df[[i]]))
  {
    num_cols <- c(num_cols,i)
  }
  else
  {
    cat_cols <- c(cat_cols,i)
  }
}

cat("Numeric: ",paste(num_cols,collapse=", "),"\n\n")
cat("Categorical: ",paste(cat_cols,collapse=", "),"\n")
```


Count NA and fill NA

```{r}
# Count how many NA value in each column
for (i in names(df))
{
  cat(i,": ",sum(is.na(df[[i]])),"\n")
}

# Fill all the NA value in non numeric variable with mode and using mean to fill all the NA value in numeric variable
for (i in cat_cols)
{
  # names is used to extract the name and not the frequency value
  mode <- names(sort(table(df[[i]]), decreasing=TRUE)[1])
  df[[i]][is.na(df[[i]])] <- mode
}

for (i in num_cols)
{
  mean <- mean(df[[i]], na.rm = TRUE)
  df[[i]][is.na(df[[i]])] <- mean
}
```

Change some variables that is categorical to factor data type with certain levels

```{r}
df$Region <- factor(df$Region, levels = unique(df$Region))
CekUnique("OnlineClass_Rating")
df$OnlineClass_Rating <- factor(df$OnlineClass_Rating, levels = c("Very poor","Poor","Average","Good","Excellent"))
df$OnlineClass_Medium <- factor(df$OnlineClass_Medium, levels = unique(df$OnlineClass_Medium))
df$SosMed_Medium <- factor(df$SosMed_Medium, levels = unique(df$SosMed_Medium))
CekUnique("WeightChange")
df$WeightChange <- factor (df$WeightChange, levels = c("Decreased","Remain Constant","Increased"))
df$Having_HealthIssue <- factor(df$Having_HealthIssue)
df$Stress_Busters <- factor(df$Stress_Busters, levels = unique(df$Stress_Busters))
df$Time_Utilized <- factor(df$Time_Utilized)
df$Connected_with_Family_Friends_Relatives <- factor(df$Connected_with_Family_Friends_Relatives)
df$Most_Missed_Things <- factor(df$Most_Missed_Things, levels = unique(df$Most_Missed_Things))
```

Crosscheck the structure of our dataframe after preprocessed the data

```{r}
str(df)
```

# 1. Assess genereal characteristics of the dataset

```{r}
summary(df)
```

Factor Variables: the summary provides frequency distribution of each level for variables like Region, OnlineClass_Rating, OnlineClass_Medium, etc.

-   Region: most respondents live in Delhi National Capital Region
-   OnlineClass_Rating: most respondents rated their online classes as "Average", followed by "Good", "Excellent", "Very poor", and "Poor"
-   OnlineClass_Medium: majority of respondents used a Laptop/Desktop for online classes, followed by a Smartphone, Tablet, Any Gadget, and combination of Smartphone or Laptop/Desktop.
-   etc ...

Numeric Variables: the summary provides descriptive statistics for variables like Age, OnlineClass_Time, SelfStudy_Duration, etc.

-   Age: the average age of respondents is approximately 20.17 years, with minimum of 7 years and maximum of 59 years
-   OnlineClass_Time: on average, respondents spent 3.209 hours on online classes, with some minumum of 0 hours and others spending up to 10 hours
-   etc ...

Note: (Other) combine all remaining levels of a factor variable with more than six levels into a single “other” category Numeric variables provide mean value and Tukey’s five-number summary which includes the minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum

```{r}
BasicSummary(df)
```

Most of the variables in this data frame have understandable names which is really important Of the 18 variables in the df data frame, 10 is factor and the remaining columns are numeric

-   variable: name or label of the variable
-   type: data type of the variable (ex: character, numeric)
-   levels: number of unique categories/ values
-   topLevel: most frequent category/value
-   topCount: frequency of the top-level category/value
-   topFrac: proportion of the top-level category/value
-   missFreq: count of missing values
-   missFrac: proportion of missing values

# 2. Examine descriptive stats

```{r}
num_df <- subset(df,select = num_cols) # make new data frame with consisting only numeric/ integer data type
```

these statistical measures provide a view of a dataset's distribution:

-   Central Tendency: mean and median help to understand the central value of the data.
-   Variability: variance and standard deviation measure the spread of the data points around the mean
-   Range: quick insight into the spread between the minimum and maximum values
-   Distribution and Spread: interquartile range (IQR) provides insights about the spread of the middle 50% of the data, giving a solid measure of the data's distribution that is less influenced by extreme values or outliers

# 3. Examine Exploratory visualization

```{r}
# Age of Respondent visualization (group to some categories with intervals of 10)
age_plot <- ggplot(df, aes(x = Age, fill=Having_HealthIssue)) + # x axis represents age, and the color will be differentiate by having health issue
  geom_histogram(color = "black", binwidth = 10) + # our histogram will have black outline and the bars are group per 10 intervaols
  # add label to our graph
  labs(title = "Distribution of Respondents by Age",
       x = "Age",
       y = "Number of Respondents",
       fill = "Having Health Issue?") +
  scale_fill_brewer(palette = "Set2") + # filling colors using color palettes from the RColorBrewer package
  coord_flip() # swapping the x and y axis, it is useful when the data categorical name is too long and it doesn't fit in the x axis
print(age_plot)

# Respondent's Region of Residence visualization
residence_plot <- pie(table(df$Region), # table is used to create a contingency table of the counts of each category
    main = "Distribution of Respondents by Region of Residence",
    col = c("purple", "pink"))
# no need to use print function when displaying pie

```

Most of the respondents are in their 20s who don't have any health issue More than half of the respondents live in Delhi National Capital Region

```{r}
# Respondent's Preferred Social Media Platform visualization
sosmed_plot <- df %>% # %>% is a pipe operator to chain multiple operation
  group_by(SosMed_Medium) %>% # group data by SosMed_Medium
  summarise(freqCount = n()) %>% # returns one row for each combination of grouping variables; n() -> counts the number of frequency count in each group
  ggplot(aes(x=reorder(SosMed_Medium, freqCount),  y=freqCount, fill=freqCount)) + # reorder the sosmed_medium factor based on freqCount in ascending order, eventhough it looks like descending because coord_flip is used here
  geom_bar(color="black", stat="identity") + # stat = "identity" -> height of the bars is determined by freqCount
  labs(title = "Distribution of Respondents by Preferred Social Media Platform",
       x = "Social Media Platforms",
       y = "Number of Respondents",
       fill = "Frequency Count") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") + # filling colors using gradient with starting color light blue and end with red
  coord_flip()
print(sosmed_plot)

# Top 20 Respondent's Preferred Stress Busters
stress_plot <- df %>%
  group_by(Stress_Busters) %>% 
  summarise(freqCount = n()) %>%
  top_n(10, freqCount) %>%  # filter the top 10 stress busters
  ggplot(aes(x=reorder(Stress_Busters, freqCount),  y=freqCount, fill=freqCount)) +
  geom_bar(color="black", stat="identity") +
  labs(title = "Distribution of Respondents by Preferred Stress Busters (Top 10)",
       x = "Activity",
       y = "Number of Respondents",
       fill = "Frequency Count") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_flip()
print(stress_plot)

# Top 10 Things the Respondent Miss the Most
miss_plot <- df %>%
  group_by(Most_Missed_Things) %>% 
  summarise(freqCount = n()) %>%
  top_n(10, freqCount) %>%
  ggplot(aes(x=reorder(Most_Missed_Things, freqCount),  y=freqCount, fill=freqCount)) +
  geom_bar(color="black", stat="identity") +
  labs(title = "Distribution of Respondents by Things they Miss the Most (Top 10)",
       x = "Object/ Subject",
       y = "Number of Respondents",
       fill = "Frequency Count") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_flip()
print(miss_plot)

```

Most of the respondent prefer to use Instagram as their social media, followed by WhatsApp and Youtube Most of the respondent prefer to listen to music as their stress busters, followed by play online game and watch web series Top 3 things respodent miss the most are school/ college, friends and relatives, and also travelling

```{r}
# store the column name of variables related to duration
duration_cols <- c('OnlineClass_Time', 'SelfStudy_Duration', 'Fitness_Duration',
                   'Sleeping_Duration', 'SosMed_Duration', 'WatchingTV_Duration')

# calculate mean duration for each activity
mean_durations <- sapply(duration_cols, function(col) mean(df[[col]], na.rm = TRUE)) # a function which take the parameter col to calculate each mean
names(mean_durations) <- duration_cols # labeling the vector

# create a long-format data frame
df_long <- stack(df[, duration_cols]) # stack the duration_cols -> resulting a data frame with 2 columns (the value and the names of stacked columns)
names(df_long) <- c("Duration", "Activity")

# reorder activities by mean of duration
ordered_activities <- names(sort(mean_durations))
df_long$Activity <- factor(df_long$Activity, levels = ordered_activities)

# create the box plot
duration_plot <- ggplot(df_long, aes(y = Activity, x = Duration)) +
  geom_boxplot(fill="gray") +
  labs(title = "Distribution of Time Spent by Activity",
       x = "Duration (Hours(s))",
       y = "Type of Activity")

print(duration_plot)
```

The activity that takes the longest duration in sleeping, followed by online class, self study, using social media, watching tv, lastly fitness Self study has the most outliers compared to the other activities Self study is very skewed to the right and fitness duration is skewed to the left

```{r}
# remove outliers in duration column based on the outlier we found in the boxplot
for (i in duration_cols)
{
  outliers <- boxplot.stats(df[[i]])$out # identify outliers
  df <- df[!df[[i]] %in% outliers, ] # remove the whole row if it contains outliers
}

str(df)
```

now our data is reduced to 1048 observations

```{r}
p1 <- ggplot(df, aes(x = Having_HealthIssue, y = OnlineClass_Time)) +
  # differentiate color based on Having_HealthIssue variable
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on Online Class by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on Online Class")
print(p1)

p2 <- ggplot(df, aes(x = Having_HealthIssue, y = SelfStudy_Duration)) +
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on Self Study by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on Self Study")
print(p2)

p3 <- ggplot(df, aes(x = Having_HealthIssue, y = Fitness_Duration)) +
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on Fitness by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on Fitness")
print(p3)

p4 <- ggplot(df, aes(x = Having_HealthIssue, y = Sleeping_Duration)) +
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on Sleep by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on Sleep")
print(p4)

p5 <- ggplot(df, aes(x = Having_HealthIssue, y = SosMed_Duration)) +
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on Social Media by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on Social Media")
print(p5)

p6 <- ggplot(df, aes(x = Having_HealthIssue, y = WatchingTV_Duration)) +
  geom_boxplot(color="black", fill="gray") +
  coord_flip() +
  labs(title="Time spent on TV by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Time spent on TV")

print(p6)
```

P1 shows that respondents who had a health problem during the lockdown spent less time in online classes than those who didn't P2 shows that respondents who had a health problem during the lockdown spent less time on self-study than those who didn't P3 shows that respondents who had a health problem during the lockdown spent about the same amount of time exercising as those who didn't P4 shows that respondents who had a health problem during the lockdown spent less time sleeping than those who didn't P5 shows that respondents who had a health problem during the lockdown spent about the same amount of time on social media as those who didn't P6 shows that respondents who had a health problem during the lockdown spent less time watching TV than those who didn't

```{r}
meal_health_plot <- ggplot(df, aes(x = Having_HealthIssue, y = NumberOfMeals)) +
  geom_violin(color="black", fill="gray") +
  coord_flip() +
  labs(title="Number of Meals a Day by Health issue during lockdown", 
       x="Health issue during lockdown", 
       y="Number of Meals a Day") +
  scale_fill_brewer(palette="Set1") + # set color palette to fill the graph
  theme(legend.position = "none")
print(meal_health_plot)

weight_change_plot <- ggplot(df, aes(x=NumberOfMeals, y=WeightChange, fill=WeightChange)) +
  geom_density_ridges() +
  labs(title = "Change in Weight vs. Number of Meals per Day",
       x = "Number of Meals per Day",
       y = "Change in Weight",
       fill = "Change in Weight") +
  theme(axis.text.y = element_blank()) # hide the y-axis because it isn't used in this graph

print(weight_change_plot)
```

Majority of the respondents eat 3 times a day, followed by 2 times and 4 times Respondents with no health issue tend to eat more than the one who's health issue

Respondents who eat less than 3 times a day tend to lose weight Respondents who eat more than 3 times a day tend to gain weight Majority of respondents who eat 3 times a day have constant weight

# 4. Check anomalies

```{r}
FindOutliers(df$NumberOfMeals)$summary
```

The first column is the name of the outlier detection rule applied, the second column is the total number of observations and the third one is the number of missing observations (i.e., data records coded as NA), and the fourth column gives the number of outliers detected by each rule. The next two columns show the lower and upper outlier detection limits The final two columns show the lower and upper limits of the non-outlying data values

We can see that the three-sigma rule identifies only 3 outliers, while hampel identifies 505 outliers, and boxplot rule identify 45 outliers.

```{r}
FindOutliers(df$OnlineClass_Time)$summary
```

We can see that the three-sigma rule identifies only 0 outliers, while hampel identifies 31 outliers, and boxplot rule identify 107 outliers.

```{r}
FindOutliers(df$SelfStudy_Duration)$summary
```

We can see that the three-sigma rule identifies only 0 outliers, while hampel identifies 13 outliers, and boxplot rule identify 72 outliers.

```{r}
FindOutliers(df$Fitness_Duration)$summary
```

We can see that all the rules identifies 0 outliers.

```{r}
FindOutliers(df$Sleeping_Duration)$summary
```

We can see that both three-sigma amd hampel rules identifies 0 outliers, and boxplot rule identify 41 outliers.

```{r}
FindOutliers(df$SosMed_Duration)$summary
```

We can see that all the rules identifies 0 outliers.

```{r}
FindOutliers(df$WatchingTV_Duration)$summary
```

We can see that the three-sigma rule identifies 11 outliers, and both hample and boxplot rule identify 0 outliers.

Removing outliers based on three sigma rule

```{r}
# function to remove outliers using three-sigma rule: data outside the range of mean +-3 × standard deviation are considered outliers
remove_outliers_3sigma <- function(df, col_name) {
  mean_val <- mean(df[[col_name]], na.rm = TRUE) # calculate mean with NA value removed
  sd_val <- sd(df[[col_name]], na.rm = TRUE) # calculate std with NA value removed
  
  lower_limit <- mean_val - 3 * sd_val
  upper_limit <- mean_val + 3 * sd_val
  
  # keep the rows where the values in the specified column (col_name) are within the lower and upper limit
  df_filtered <- df[df[[col_name]] >= lower_limit & df[[col_name]] <= upper_limit, ] #buat ngasi syarat hrs ada koma [,]
  
  return(df_filtered)
}

# remove outliers using our function
df <- remove_outliers_3sigma(df, "NumberOfMeals")
df <- remove_outliers_3sigma(df, "NumberOfMeals")
df <- remove_outliers_3sigma(df, "OnlineClass_Time")
df <- remove_outliers_3sigma(df, "SelfStudy_Duration")
df <- remove_outliers_3sigma(df, "Fitness_Duration")
df <- remove_outliers_3sigma(df, "Sleeping_Duration")
df <- remove_outliers_3sigma(df, "SosMed_Duration")
df <- remove_outliers_3sigma(df, "WatchingTV_Duration")
```

### 5. Relation Between Variables

Check condition for pearson correlation

```{r}
col_names = c()
sph_test = c()
for (i in num_cols)
{
  # check for only numeric/ integer variables
  if ((is.numeric(df[[i]]) || is.integer(df[i])))
  {
    col_names <- c(col_names, i)
    ans <- shapiro.test(df[[i]])$p.value
    sph_test <- c(sph_test, ans)
  }
}
sph_df = data.frame(Name = col_names, PVal = sph_test)
sph_df[order(sph_df$PVal),]
```

None of the variables meet the criteria for normal distribution because none of the p-value is \> than 0.05 -\> reject the null hypothesis; null hypothesis accepted criteria: p-value \> 0.05 INI SALAH -\> So we can conclude that our numerical data doesn't have normal Distribution so we can't use the pearson correlation

```{r}
df$OnlineClass_Time_log = log(df$OnlineClass_Time+1)
shapiro.test(df$OnlineClass_Time_log)

df$OnlineClass_Time_sr = sqrt(df$OnlineClass_Time+1)
shapiro.test(df$OnlineClass_Time_sr)
```

```{r}
num_df <- subset(df,select = num_cols) #update the num_df after removing some of the observations

# convert YES/NO factor columns to numeric (1 for YES, 0 for NO)
num_df$Having_HealthIssue <- as.numeric(df$Having_HealthIssue == "YES")
num_df$Time_Utilized <- as.numeric(df$Time_Utilized == "YES")
num_df$Connected_with_Family_Friends_Relatives <- as.numeric(df$Connected_with_Family_Friends_Relatives == "YES")

# convert WeightChange to numeric based on mappings
num_df$WeightChange <- ifelse(df$WeightChange == "Increased", 2,
                          ifelse(df$WeightChange == "Decreased", 0, 1))

c <- cor(num_df)
# View(c)
corrplot(c, type="upper", method="number",
         number.cex=0.7,  # font size of correlation numbers
         tl.cex=0.7,      # font size of column/row names
         tl.srt=60)
```

```{r}
# check correlation of having health issue category with quantitative data which is duration of different activities
for (i in duration_cols)
{
  cat(i,": ",cor(num_df[[i]], num_df$Having_HealthIssue),"\n")
}
```

There is generally a weak correlation between time spent on various activities and the likelihood of having a health issue. Increased durations in online classes, fitness, and watching TV show slight negative associations with health issues. In contrast, spending more time on social media has a insignificant positive correlation with health issues. Overall, these correlations are weak, indicating that individual activities may not be strong predictors of Having_HealthIssue. Other unmeasured factors might influence these relationships.

```{r}
# compute the total time for productive and non productive activity
num_df$TotalP = num_df$SelfStudy_Duration + num_df$Fitness_Duration
num_df$TotalN = num_df$SosMed_Duration + num_df$WatchingTV_Duration
# View(num_df)

# compute correlation
correlations <- cor(num_df[, c("TotalP", "TotalN", "Time_Utilized")])
print(correlations)

ggplot(num_df, aes(x = TotalP, 
                     y = Time_Utilized)) +
  geom_point(color="green4") +
  labs(title = "Correlation Between SelfStudy and Fitness Duration with Time_Utilized")+
  geom_smooth(method="lm")

```

The total time spent on productive activities (self study and fitness) increases, there is a slight tendency for the overall time utilized to also increase

```{r}
correlations <- cor(num_df[, c("NumberOfMeals", "WeightChange")])
print(correlations)

ggplot(num_df, aes(x = NumberOfMeals, 
                     y = WeightChange)) +
  geom_point(color="green4") +
  labs(title = "Weight Change by Number Of Meals")+
  geom_smooth(method="lm")
```

This suggests a weak positive relationship: as the number of meals consumed increases, there is a slight tendency for weight change to also increase.

Using chi-square test to measure categorical variable's correlation

```{r}
col_pair = c()
chisq_pv = c()
# harus dikasi ( ) klo ga nanti error
for (i in 2:(length(cat_cols)-1))
{
  for (j in (i+1):length(cat_cols))
  {
    col_pair <- c(col_pair,paste(cat_cols[i],",", cat_cols[j]))
    ans <- chisq.test(df[[cat_cols[i]]], df[[cat_cols[j]]])$p.value
    chisq_pv <- c(chisq_pv, ans)
    # print(chisq.test(df[[cat_cols[i]]], df[[cat_cols[j]]])$p.value)
  }
}

chi_df = data.frame(Name = col_pair, PVal = chisq_pv)
head(chi_df[order(chi_df$PVal),], n=10)
```

Some of the variables have significant connection because they reject the null hypothesis (variables are independent) null hypothesis accepted criteria: p-value \> 0.05 null hypothesis rejected criteria: p-value \< 0.05

Since we get a p-value of less than the significance level of 0.05, We are able to reject the null hypothesis that these two variables are independent in the population from which this sample was drawn

```{r}
tbl1 <- table(df$OnlineClass_Rating, df$Time_Utilized) # creates a contingency table: a frequency table that displays the distribution of one categorical variable in rows and another in columns
print(PercTable(tbl1))
print(PercTable(tbl1, margin=1)) # sum of percentage per row
print(PercTable(tbl1, margin=2)) # sum of percentage per column
```

Respondents who spent more time utilizing their time generally had more positive ratings compared to those who spent less time

```{r}
# computes a variety of association statistics for the contingency table, such as Chi-square test statistic, Cramér's V, and contingency coefficients, to determine the strength and significance of the association between the two categorical variables
assocstats(tbl1)

tbl1_plt = ggplot(df, aes(x = OnlineClass_Rating, fill = Time_Utilized)) + 
  geom_bar(position = position_dodge(preserve = "single")) + # add a bar plot where bars of different categories are placed side by side, but bars with only one value will remain centered without dodging
  labs(y = "Frequency (in tens)", 
       title = "Online Class Rating by Time Utilized",
       fill = "Time Utilized?") +
  scale_y_continuous(labels = function(x) x / 10)
print(tbl1_plt)
```

P(\> X\^2) itu p value klo \> 0.05 brrti null hipotesis (variabel independet) ditrima klo \< 0.05 brarti ada correlation

There are no fixed rules on interpreting the value of Cramer's V, but here’s a guide: weak (0 to 0.2); moderate (0.2 to 0.3); strong (0.3 to 0.5); redundant (0.5 to 0.99 - the two variables are probably measuring the same concept)

So in this case, there is an association between variable online class rating and time utilized with moderate strength association

```{r}
tbl2 <- table(df$Connected_with_Family_Friends_Relatives, df$Time_Utilized)
print(PercTable(tbl2))
print(PercTable(tbl2, margin=1))
print(PercTable(tbl2, margin=2))
```

```{r}
assocstats(tbl2)

tbl2_plt = ggplot(df, aes(x = Connected_with_Family_Friends_Relatives, fill = Time_Utilized)) + 
  geom_bar(position = position_dodge(preserve = "single")) +
  labs(y = "Frequency (in hundreds)", 
       title = "Connected with Family Friends Relatives? by Time Utilized",
       fill = "Time Utilized?") +
  scale_y_continuous(labels = function(x) x / 100)
print(tbl2_plt)
```

# 6. Summary in Data Dictionary

```{r}
# Data Dictionary

description <- "Based on the third SDG, health and well-being, this EDA focuses on 'well-being in the midst of the Covid-19 pandemic'. The dataset includes information on individuals' daily activities, health problems and stress relievers. It aims to provide insights that can contribute to improving mental and physical health, in line with the SDG goal of ensuring healthy lives and promoting well-being for all at all ages."

# format
f_row <- 1182
f_col <- 19

fields <- data.frame(
  Field_Name = c("ID", "Region", "Age", "OnlineClass_Time", "OnlineClass_Rating",
                 "OnlineClass_Medium", "SelfStudy_Duration", "Fitness_Duration",
                 "Sleeping_Duration", "SosMed_Duration", "SosMed_Medium",
                 "WatchingTV_Duration", "NumberOfMeals", "WeightChange", 
                 "Having_HealthIssue", "Stress_Busters", "Time_Utilized",
                 "Connected_with_Family_Friends_Relatives", "Most_Missed_Things"),
  Description = c("Identifier for the individual", "Geographical region of residence", 
                  "Age of the individual", "Time spent on online classes", 
                  "Rating of online classes", "Device used for online classes", 
                  "Duration of self-study", "Duration of fitness activities", 
                  "Duration of sleep", "Duration of time spent on social media", 
                  "Platform used for social media", "Duration of time spent watching TV", 
                  "Number of meals consumed per day", "Change in weight status", 
                  "Indicates if the individual has a health issue", "Activities to reduce stress", 
                  "Indicates if time was utilized effectively", "Connected with family, friends, or relatives", 
                  "Things missed the most during lockdown"),
  Format = c("Character", "Factor", "Numeric", "Numeric", "Factor", "Factor", "Numeric", "Numeric",
             "Numeric", "Numeric", "Factor", "Numeric", "Numeric", "Factor", "Factor",
             "Factor", "Factor", "Factor", "Factor"),
  Units_Levels = c("Unique identifier", "Delhi-NCR, Outside Delhi-NCR", "Years (e.g., 21, 22)", 
                   "Hours (e.g., 1.5, 2.0)", "Very poor, Poor, Average, Good, Excellent", 
                   "Gadget Type (e.g., Laptop/Desktop, Tablet, Mobile)", "Hours (e.g., 1.0, 1.5)", 
                   "Hours (e.g., 0.5, 1.0)", "Hours (e.g., 6, 7)", "Hours (e.g., 1, 2)", 
                   "Various platforms (e.g., Facebook, Instagram)", "Hours (e.g., 1, 2)", 
                   "Count (e.g., 2, 3, 4)", "Decreased, Remain Constant, Increased", 
                   "NO, YES", "List of activities", "NO, YES", "NO, YES", 
                   "School/college, Outdoor activities, Social gatherings, etc.")
)

# source
source_info <- "The dataset was collected through a comprehensive survey by conducting a web-based survey to students via Google online platforms from July 13 to July 17, 2020."

# published references
published_refs <- c(
  "Kunal Chaturvedi, Dinesh Vishwakarma, Nidhi Singh. (2020). COVID-19 and its impact on education, social life and mental health of students: A Survey. Children and Youth Services Review, 121. https://doi.org/10.1016/j.childyouth.2020.105866\n",
  "Kunal Chaturvedi. (2020). COVID-19 and its impact on students. Kaggle. Available at: https://www.kaggle.com/datasets/kunal28chaturvedi/covid19-and-its-impact-on-students/data"
)

# data anomalies
data_anomalies <- "Outliers were identified using the three-sigma rule and then removed from the dataset."

# features causing confusion
confusing_features <- "The categorical variable 'Time_Utilized' may be confused with actual time durations mentioned in the dataset. 'Time_Utilized' indicates if the time was used effectively (Yes) or not (No)."

conclusion <- "The study suggests that the duration of time spent on activities like online classes, self-study, etc isn't directly linked to students' health. Nonetheless, it's concerning that over half of the participants didn't make optimal use of their time during the lockdown. This ineffective time management could potentially lead to negative health effects. It's important to tackle this problem by helping students better manage their time and stay engaged during online classes."

# print data dictionary
cat("Description:\n", description, "\n\n")
cat("Format:\n")
print(fields)
cat("\nSource:\n", source_info, "\n\n")
cat("Published References:\n")
cat(published_refs, sep = "\n")
cat("\n\nData Anomalies:\n", data_anomalies, "\n\n")
cat("Features Causing Confusion:\n", confusing_features, "\n\n")
cat("Conclusion:\n", conclusion, "\n")
```
